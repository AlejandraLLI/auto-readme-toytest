{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import logging.config\n",
    "import base64\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from github import Github\n",
    "import src.github_utils as gu\n",
    "\n",
    "from langchain.document_loaders.base import BaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, Language\n",
    "from langchain.llms import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "GITHUB_API_TOKEN = os.getenv(\"GITHUB_API_TOKEN\")\n",
    "OPEN_API_TOKEN = os.getenv(\"OPENAI_API_TOKEN\")\n",
    "PINECONE_API_TOKEN = os.getenv(\"PINECONE_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<github.MainClass.Github at 0x11eaba010>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Github(GITHUB_API_TOKEN)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name = \"hyeniii/auto-readme\"\n",
    "repo = g.get_repo(repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ContentFile(path=\".gitignore\"),\n",
       " ContentFile(path=\"LICENSE\"),\n",
       " ContentFile(path=\"README.md\"),\n",
       " ContentFile(path=\"config\"),\n",
       " ContentFile(path=\"requirements.txt\"),\n",
       " ContentFile(path=\"sandbox.py\"),\n",
       " ContentFile(path=\"src\")]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents = repo.get_contents(\"\")\n",
    "contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.gitignore': 'LmVudgoudmVudi8KLnZzY29kZS8KKi5sb2cKKi5weWM=\\n',\n",
       " 'LICENSE': 'TUlUIExpY2Vuc2UKCkNvcHlyaWdodCAoYykgMjAyMyBIeWUgV29uIChOaWNv\\nbGUpIEh3YW5nCgpQZXJtaXNzaW9uIGlzIGhlcmVieSBncmFudGVkLCBmcmVl\\nIG9mIGNoYXJnZSwgdG8gYW55IHBlcnNvbiBvYnRhaW5pbmcgYSBjb3B5Cm9m\\nIHRoaXMgc29mdHdhcmUgYW5kIGFzc29jaWF0ZWQgZG9jdW1lbnRhdGlvbiBm\\naWxlcyAodGhlICJTb2Z0d2FyZSIpLCB0byBkZWFsCmluIHRoZSBTb2Z0d2Fy\\nZSB3aXRob3V0IHJlc3RyaWN0aW9uLCBpbmNsdWRpbmcgd2l0aG91dCBsaW1p\\ndGF0aW9uIHRoZSByaWdodHMKdG8gdXNlLCBjb3B5LCBtb2RpZnksIG1lcmdl\\nLCBwdWJsaXNoLCBkaXN0cmlidXRlLCBzdWJsaWNlbnNlLCBhbmQvb3Igc2Vs\\nbApjb3BpZXMgb2YgdGhlIFNvZnR3YXJlLCBhbmQgdG8gcGVybWl0IHBlcnNv\\nbnMgdG8gd2hvbSB0aGUgU29mdHdhcmUgaXMKZnVybmlzaGVkIHRvIGRvIHNv\\nLCBzdWJqZWN0IHRvIHRoZSBmb2xsb3dpbmcgY29uZGl0aW9uczoKClRoZSBh\\nYm92ZSBjb3B5cmlnaHQgbm90aWNlIGFuZCB0aGlzIHBlcm1pc3Npb24gbm90\\naWNlIHNoYWxsIGJlIGluY2x1ZGVkIGluIGFsbApjb3BpZXMgb3Igc3Vic3Rh\\nbnRpYWwgcG9ydGlvbnMgb2YgdGhlIFNvZnR3YXJlLgoKVEhFIFNPRlRXQVJF\\nIElTIFBST1ZJREVEICJBUyBJUyIsIFdJVEhPVVQgV0FSUkFOVFkgT0YgQU5Z\\nIEtJTkQsIEVYUFJFU1MgT1IKSU1QTElFRCwgSU5DTFVESU5HIEJVVCBOT1Qg\\nTElNSVRFRCBUTyBUSEUgV0FSUkFOVElFUyBPRiBNRVJDSEFOVEFCSUxJVFks\\nCkZJVE5FU1MgRk9SIEEgUEFSVElDVUxBUiBQVVJQT1NFIEFORCBOT05JTkZS\\nSU5HRU1FTlQuIElOIE5PIEVWRU5UIFNIQUxMIFRIRQpBVVRIT1JTIE9SIENP\\nUFlSSUdIVCBIT0xERVJTIEJFIExJQUJMRSBGT1IgQU5ZIENMQUlNLCBEQU1B\\nR0VTIE9SIE9USEVSCkxJQUJJTElUWSwgV0hFVEhFUiBJTiBBTiBBQ1RJT04g\\nT0YgQ09OVFJBQ1QsIFRPUlQgT1IgT1RIRVJXSVNFLCBBUklTSU5HIEZST00s\\nCk9VVCBPRiBPUiBJTiBDT05ORUNUSU9OIFdJVEggVEhFIFNPRlRXQVJFIE9S\\nIFRIRSBVU0UgT1IgT1RIRVIgREVBTElOR1MgSU4gVEhFClNPRlRXQVJFLgo=\\n',\n",
       " 'README.md': 'IyBBdXRvLVJlYWRtZQoKQXV0b21hdGljYWxseSBnZW5lcmF0ZSBgcmVhZG1l\\nLm1kYCBmaWxlcyBmb3IgeW91ciByZXBvc2l0b3JpZXMgYnkgcGFyc2luZyB0\\naGUgY29kZSBhbmQgc3VtbWFyaXppbmcgaXQgdXNpbmcgT3BlbmFpIEFQSS4K\\nCiMjIEZlYXR1cmVzCgotIFBhcnNlIEdpdEh1YiByZXBvc2l0b3JpZXMgd2l0\\naG91dCBkb3dubG9hZGluZyB0aGVtLgotIFN1bW1hcml6ZSBjb2RlIHVzaW5n\\nIExhbmdjaGFpbi4KLSBHZW5lcmF0ZSBodW1hbi1yZWFkYWJsZSBzdW1tYXJp\\nZXMgd2l0aCBPcGVuQUkncyBHUFQgbW9kZWwuCgojIyBQcmVyZXF1aXNpdGVz\\nCgotIFB5dGhvbiAzLjgrCi0gR2l0SHViIEFQSSBUb2tlbiAoaHR0cHM6Ly9n\\naXRodWIuY29tL3NldHRpbmdzL3Rva2VucykKLSBPcGVuQUkgQVBJIEtleSAo\\naHR0cHM6Ly9iZXRhLm9wZW5haS5jb20vc2lnbnVwKQoKIyMgSW5zdGFsbGF0\\naW9uCgoxLiBDbG9uZSBSZXBvc2l0b3J5CjIuIENyZWF0ZSBhIHZpcnR1YWwg\\nZW52aXJvbm1lbnQgYHB5dGhvbiAtbSB2ZW52IC52ZW52YCBhbmQgaW5zdGFs\\nbCBwYWNrYWdlcyBpbiBgcmVxdWlyZW1lbnRzLnR4dGAKMi4gQ3JlYXRlIC5l\\nbnYgZmlsZSBhdCB0aGUgcm9vdCBvZiBkaXJlY3RvcnkKCmBgYGJhc2gKR0lU\\nSFVCX0FQSV9UT0tFTj08YWRkLXRva2VuLWhlcmU+Ck9QRU5BSV9BUElfVE9L\\nRU49PGFkZC10b2tlbi1oZXJlPgpgYGAK\\n',\n",
       " 'config': {'config/logs': {'config/logs/local.conf': 'W2xvZ2dlcnNdCmtleXM9cm9vdCxzcmMKCltoYW5kbGVyc10Ka2V5cz1jb25z\\nb2xlSGFuZGxlcixmaWxlSGFuZGxlcgoKW2Zvcm1hdHRlcnNdCmtleXM9c2Ft\\ncGxlRm9ybWF0dGVyCgpbbG9nZ2VyX3Jvb3RdCmxldmVsPUlORk8KaGFuZGxl\\ncnM9Y29uc29sZUhhbmRsZXIsZmlsZUhhbmRsZXIKcHJvcGFnYXRlPTAKClts\\nb2dnZXJfc3JjXQpsZXZlbD1JTkZPCmhhbmRsZXJzPWNvbnNvbGVIYW5kbGVy\\nLGZpbGVIYW5kbGVyCnF1YWxuYW1lPXNyYwpwcm9wYWdhdGU9MAoKW2hhbmRs\\nZXJfY29uc29sZUhhbmRsZXJdCmNsYXNzPVN0cmVhbUhhbmRsZXIKbGV2ZWw9\\nSU5GTwpmb3JtYXR0ZXI9c2FtcGxlRm9ybWF0dGVyCmFyZ3M9KHN5cy5zdGRv\\ndXQsKQoKW2hhbmRsZXJfZmlsZUhhbmRsZXJdCmNsYXNzPUZpbGVIYW5kbGVy\\nCmxldmVsPUlORk8KZm9ybWF0dGVyPXNhbXBsZUZvcm1hdHRlcgphcmdzPSgn\\nY29uZmlnL2xvZ3MvbG9ncy5sb2cnLCkKCltmb3JtYXR0ZXJfc2FtcGxlRm9y\\nbWF0dGVyXQpmb3JtYXQ9JShhc2N0aW1lKXMgLSAlKG5hbWUpcyAtICUobGV2\\nZWxuYW1lKXMgLSAlKG1lc3NhZ2UpcwpkYXRlZm10PSVZLSVtLSVkICVIOiVN\\nOiVT\\n'}},\n",
       " 'requirements.txt': 'YWlvaHR0cD09My44LjYKYWlvc2lnbmFsPT0xLjMuMQphc3luYy10aW1lb3V0\\nPT00LjAuMwphdHRycz09MjMuMS4wCmNlcnRpZmk9PTIwMjMuNy4yMgpjZmZp\\nPT0xLjE2LjAKY2hhcnNldC1ub3JtYWxpemVyPT0zLjMuMgpjcnlwdG9ncmFw\\naHk9PTQxLjAuNQpEZXByZWNhdGVkPT0xLjIuMTQKZnJvemVubGlzdD09MS40\\nLjAKaWRuYT09My40Cm11bHRpZGljdD09Ni4wLjQKb3BlbmFpPT0wLjI4LjEK\\ncHljcGFyc2VyPT0yLjIxClB5R2l0aHViPT0yLjEuMQpQeUpXVD09Mi44LjAK\\nUHlOYUNsPT0xLjUuMApweXRob24tZGF0ZXV0aWw9PTIuOC4yCnB5dGhvbi1k\\nb3RlbnY9PTEuMC4wCnJlcXVlc3RzPT0yLjMxLjAKc2l4PT0xLjE2LjAKdHFk\\nbT09NC42Ni4xCnR5cGluZ19leHRlbnNpb25zPT00LjguMAp1cmxsaWIzPT0y\\nLjAuNwp3cmFwdD09MS4xNS4wCnlhcmw9PTEuOS4yCg==\\n',\n",
       " 'sandbox.py': 'aW1wb3J0IG9zCmltcG9ydCBhcmdwYXJzZQppbXBvcnQgbG9nZ2luZwppbXBv\\ncnQgbG9nZ2luZy5jb25maWcKCmZyb20gZG90ZW52IGltcG9ydCBsb2FkX2Rv\\ndGVudgpmcm9tIGdpdGh1YiBpbXBvcnQgR2l0aHViCmltcG9ydCBzcmMuZ2l0\\naHViX3V0aWxzIGFzIGd1Cgpsb2dnaW5nLmNvbmZpZy5maWxlQ29uZmlnKCJj\\nb25maWcvbG9ncy9sb2NhbC5jb25mIikKbG9nZ2VyID0gbG9nZ2luZy5nZXRM\\nb2dnZXIoX19uYW1lX18pCgppZiBfX25hbWVfXyA9PSAiX19tYWluX18iOgog\\nICAgcGFyc2VyID0gYXJncGFyc2UuQXJndW1lbnRQYXJzZXIoCiAgICAgICAg\\nZGVzY3JpcHRpb249IkF1dG8tcmVhZG1lIgogICAgKQogICAgcGFyc2VyLmFk\\nZF9hcmd1bWVudCgKICAgICAgICAiLXIiLCAiLS1yZXBvIiwgZGVmYXVsdD0i\\naHllbmlpaS9hdXRvLXJlYWRtZSIsIGhlbHA9IlNwZWNpZnkgZ2l0aHViIHJl\\ncG9zaXRvcnkgdG8gY3JlYXRlIGEgcmVhZG1lIG9uIgogICAgKQogICAgYXJn\\ncyA9IHBhcnNlci5wYXJzZV9hcmdzKCkKCiAgICAjIExvYWQgZW52aXJvbm1l\\nbnQgdmFyaWFibGVzIGZyb20gLmVudiBmaWxlCiAgICBsb2FkX2RvdGVudigp\\nCgogICAgR0lUSFVCX0FQSV9UT0tFTiA9IG9zLmdldGVudigiR0lUSFVCX0FQ\\nSV9UT0tFTiIpCiAgICBPUEVOX0FQSV9UT0tFTiA9IG9zLmdldGVudigiT1BF\\nTkFJX0FQSV9UT0tFTiIpCgogICAgaWYgR0lUSFVCX0FQSV9UT0tFTiBpcyBO\\nb25lIG9yIE9QRU5fQVBJX1RPS0VOIGlzIE5vbmU6CiAgICAgICAgbG9nZ2Vy\\nLmVycm9yKCJBUEkgdG9rZW5zIG5vdCBmb3VuZCBpbiBlbnZpcm9ubWVudCB2\\nYXJpYWJsZXMuIikKICAgICAgICBleGl0KDEpICAjIEV4aXQgdGhlIHByb2dy\\nYW0gaWYgdG9rZW5zIGFyZSBub3Qgc2V0CgogICAgdHJ5OgogICAgICAgIGcg\\nPSBHaXRodWIoR0lUSFVCX0FQSV9UT0tFTikKICAgICAgICByZXBvID0gZy5n\\nZXRfcmVwbygicHVibGljLWFwaXMvcHVibGljLWFwaXMiKQogICAgICAgIHBy\\naW50KHJlcG8uZ2V0X3RvcGljcygpKQogICAgICAgIGxvZ2dpbmcuaW5mbygi\\nUmVjZXRyaXZpbmcgZGF0YSBmcm9tICVzIiwgcmVwby5mdWxsX25hbWUpCiAg\\nICAgICAgY29udGVudHMgPSByZXBvLmdldF9jb250ZW50cygiIikKICAgICAg\\nICBhbGxfZmlsZXMgPSBndS5nZXRfYWxsX2ZpbGVzKHJlcG8pCiAgICAgICAg\\ncHJpbnQoYWxsX2ZpbGVzKQogICAgZXhjZXB0IEV4Y2VwdGlvbiBhcyBlOgog\\nICAgICAgIGxvZ2dpbmcuZXJyb3IoIkVycm9yIG9jY3VyZWQgaW4gcmV0cmll\\ndmluZyByZXBvIGNvbnRlbnQiLCBlKQo=\\n',\n",
       " 'src': {'src/__init__.py': '',\n",
       "  'src/github_utils.py': 'ZnJvbSBnaXRodWIgaW1wb3J0IEdpdGh1YgoKZGVmIGdldF9hbGxfZmlsZXMo\\ncmVwbywgcGF0aD0iIik6CiAgICBmaWxlcyA9IHt9CiAgICBjb250ZW50cyA9\\nIHJlcG8uZ2V0X2NvbnRlbnRzKHBhdGgpCiAgICBmb3IgY29udGVudCBpbiBj\\nb250ZW50czoKICAgICAgICBpZiBjb250ZW50LnR5cGUgPT0gImRpciI6CiAg\\nICAgICAgICAgIGZpbGVzW2NvbnRlbnQucGF0aF0gPSBnZXRfYWxsX2ZpbGVz\\nKHJlcG8sIGNvbnRlbnQucGF0aCkKICAgICAgICBlbHNlOgogICAgICAgICAg\\nICBmaWxlc1tjb250ZW50LnBhdGhdID0gY29udGVudC5jb250ZW50ICMgYmFz\\nZTY0CiAgICByZXR1cm4gZmlsZXM=\\n'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = gu.get_all_files(repo)\n",
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.gitignore': '.env\\n.venv/\\n.vscode/\\n*.log\\n*.pyc',\n",
       " 'LICENSE': 'MIT License\\n\\nCopyright (c) 2023 Hye Won (Nicole) Hwang\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n',\n",
       " 'README.md': \"# Auto-Readme\\n\\nAutomatically generate `readme.md` files for your repositories by parsing the code and summarizing it using Openai API.\\n\\n## Features\\n\\n- Parse GitHub repositories without downloading them.\\n- Summarize code using Langchain.\\n- Generate human-readable summaries with OpenAI's GPT model.\\n\\n## Prerequisites\\n\\n- Python 3.8+\\n- GitHub API Token (https://github.com/settings/tokens)\\n- OpenAI API Key (https://beta.openai.com/signup)\\n\\n## Installation\\n\\n1. Clone Repository\\n2. Create a virtual environment `python -m venv .venv` and install packages in `requirements.txt`\\n2. Create .env file at the root of directory\\n\\n```bash\\nGITHUB_API_TOKEN=<add-token-here>\\nOPENAI_API_TOKEN=<add-token-here>\\n```\\n\",\n",
       " 'config': {'config/logs': {'config/logs/local.conf': \"[loggers]\\nkeys=root,src\\n\\n[handlers]\\nkeys=consoleHandler,fileHandler\\n\\n[formatters]\\nkeys=sampleFormatter\\n\\n[logger_root]\\nlevel=INFO\\nhandlers=consoleHandler,fileHandler\\npropagate=0\\n\\n[logger_src]\\nlevel=INFO\\nhandlers=consoleHandler,fileHandler\\nqualname=src\\npropagate=0\\n\\n[handler_consoleHandler]\\nclass=StreamHandler\\nlevel=INFO\\nformatter=sampleFormatter\\nargs=(sys.stdout,)\\n\\n[handler_fileHandler]\\nclass=FileHandler\\nlevel=INFO\\nformatter=sampleFormatter\\nargs=('config/logs/logs.log',)\\n\\n[formatter_sampleFormatter]\\nformat=%(asctime)s - %(name)s - %(levelname)s - %(message)s\\ndatefmt=%Y-%m-%d %H:%M:%S\"}},\n",
       " 'requirements.txt': 'aiohttp==3.8.6\\naiosignal==1.3.1\\nasync-timeout==4.0.3\\nattrs==23.1.0\\ncertifi==2023.7.22\\ncffi==1.16.0\\ncharset-normalizer==3.3.2\\ncryptography==41.0.5\\nDeprecated==1.2.14\\nfrozenlist==1.4.0\\nidna==3.4\\nmultidict==6.0.4\\nopenai==0.28.1\\npycparser==2.21\\nPyGithub==2.1.1\\nPyJWT==2.8.0\\nPyNaCl==1.5.0\\npython-dateutil==2.8.2\\npython-dotenv==1.0.0\\nrequests==2.31.0\\nsix==1.16.0\\ntqdm==4.66.1\\ntyping_extensions==4.8.0\\nurllib3==2.0.7\\nwrapt==1.15.0\\nyarl==1.9.2\\n',\n",
       " 'sandbox.py': 'import os\\nimport argparse\\nimport logging\\nimport logging.config\\n\\nfrom dotenv import load_dotenv\\nfrom github import Github\\nimport src.github_utils as gu\\n\\nlogging.config.fileConfig(\"config/logs/local.conf\")\\nlogger = logging.getLogger(__name__)\\n\\nif __name__ == \"__main__\":\\n    parser = argparse.ArgumentParser(\\n        description=\"Auto-readme\"\\n    )\\n    parser.add_argument(\\n        \"-r\", \"--repo\", default=\"hyeniii/auto-readme\", help=\"Specify github repository to create a readme on\"\\n    )\\n    args = parser.parse_args()\\n\\n    # Load environment variables from .env file\\n    load_dotenv()\\n\\n    GITHUB_API_TOKEN = os.getenv(\"GITHUB_API_TOKEN\")\\n    OPEN_API_TOKEN = os.getenv(\"OPENAI_API_TOKEN\")\\n\\n    if GITHUB_API_TOKEN is None or OPEN_API_TOKEN is None:\\n        logger.error(\"API tokens not found in environment variables.\")\\n        exit(1)  # Exit the program if tokens are not set\\n\\n    try:\\n        g = Github(GITHUB_API_TOKEN)\\n        repo = g.get_repo(\"public-apis/public-apis\")\\n        print(repo.get_topics())\\n        logging.info(\"Recetriving data from %s\", repo.full_name)\\n        contents = repo.get_contents(\"\")\\n        all_files = gu.get_all_files(repo)\\n        print(all_files)\\n    except Exception as e:\\n        logging.error(\"Error occured in retrieving repo content\", e)\\n',\n",
       " 'src': {'src/__init__.py': '',\n",
       "  'src/github_utils.py': 'from github import Github\\n\\ndef get_all_files(repo, path=\"\"):\\n    files = {}\\n    contents = repo.get_contents(path)\\n    for content in contents:\\n        if content.type == \"dir\":\\n            files[content.path] = get_all_files(repo, content.path)\\n        else:\\n            files[content.path] = content.content # base64\\n    return files'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_files = gu.decode_files(all_files)\n",
    "decoded_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.gitignore': '.env\\n.venv/\\n.vscode/\\n*.log\\n*.pyc',\n",
       " 'LICENSE': 'MIT License\\n\\nCopyright (c) 2023 Hye Won (Nicole) Hwang\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n',\n",
       " 'README.md': \"# Auto-Readme\\n\\nAutomatically generate `readme.md` files for your repositories by parsing the code and summarizing it using Openai API.\\n\\n## Features\\n\\n- Parse GitHub repositories without downloading them.\\n- Summarize code using Langchain.\\n- Generate human-readable summaries with OpenAI's GPT model.\\n\\n## Prerequisites\\n\\n- Python 3.8+\\n- GitHub API Token (https://github.com/settings/tokens)\\n- OpenAI API Key (https://beta.openai.com/signup)\\n\\n## Installation\\n\\n1. Clone Repository\\n2. Create a virtual environment `python -m venv .venv` and install packages in `requirements.txt`\\n2. Create .env file at the root of directory\\n\\n```bash\\nGITHUB_API_TOKEN=<add-token-here>\\nOPENAI_API_TOKEN=<add-token-here>\\n```\\n\",\n",
       " 'config/logs/local.conf': \"[loggers]\\nkeys=root,src\\n\\n[handlers]\\nkeys=consoleHandler,fileHandler\\n\\n[formatters]\\nkeys=sampleFormatter\\n\\n[logger_root]\\nlevel=INFO\\nhandlers=consoleHandler,fileHandler\\npropagate=0\\n\\n[logger_src]\\nlevel=INFO\\nhandlers=consoleHandler,fileHandler\\nqualname=src\\npropagate=0\\n\\n[handler_consoleHandler]\\nclass=StreamHandler\\nlevel=INFO\\nformatter=sampleFormatter\\nargs=(sys.stdout,)\\n\\n[handler_fileHandler]\\nclass=FileHandler\\nlevel=INFO\\nformatter=sampleFormatter\\nargs=('config/logs/logs.log',)\\n\\n[formatter_sampleFormatter]\\nformat=%(asctime)s - %(name)s - %(levelname)s - %(message)s\\ndatefmt=%Y-%m-%d %H:%M:%S\",\n",
       " 'requirements.txt': 'aiohttp==3.8.6\\naiosignal==1.3.1\\nasync-timeout==4.0.3\\nattrs==23.1.0\\ncertifi==2023.7.22\\ncffi==1.16.0\\ncharset-normalizer==3.3.2\\ncryptography==41.0.5\\nDeprecated==1.2.14\\nfrozenlist==1.4.0\\nidna==3.4\\nmultidict==6.0.4\\nopenai==0.28.1\\npycparser==2.21\\nPyGithub==2.1.1\\nPyJWT==2.8.0\\nPyNaCl==1.5.0\\npython-dateutil==2.8.2\\npython-dotenv==1.0.0\\nrequests==2.31.0\\nsix==1.16.0\\ntqdm==4.66.1\\ntyping_extensions==4.8.0\\nurllib3==2.0.7\\nwrapt==1.15.0\\nyarl==1.9.2\\n',\n",
       " 'sandbox.py': 'import os\\nimport argparse\\nimport logging\\nimport logging.config\\n\\nfrom dotenv import load_dotenv\\nfrom github import Github\\nimport src.github_utils as gu\\n\\nlogging.config.fileConfig(\"config/logs/local.conf\")\\nlogger = logging.getLogger(__name__)\\n\\nif __name__ == \"__main__\":\\n    parser = argparse.ArgumentParser(\\n        description=\"Auto-readme\"\\n    )\\n    parser.add_argument(\\n        \"-r\", \"--repo\", default=\"hyeniii/auto-readme\", help=\"Specify github repository to create a readme on\"\\n    )\\n    args = parser.parse_args()\\n\\n    # Load environment variables from .env file\\n    load_dotenv()\\n\\n    GITHUB_API_TOKEN = os.getenv(\"GITHUB_API_TOKEN\")\\n    OPEN_API_TOKEN = os.getenv(\"OPENAI_API_TOKEN\")\\n\\n    if GITHUB_API_TOKEN is None or OPEN_API_TOKEN is None:\\n        logger.error(\"API tokens not found in environment variables.\")\\n        exit(1)  # Exit the program if tokens are not set\\n\\n    try:\\n        g = Github(GITHUB_API_TOKEN)\\n        repo = g.get_repo(\"public-apis/public-apis\")\\n        print(repo.get_topics())\\n        logging.info(\"Recetriving data from %s\", repo.full_name)\\n        contents = repo.get_contents(\"\")\\n        all_files = gu.get_all_files(repo)\\n        print(all_files)\\n    except Exception as e:\\n        logging.error(\"Error occured in retrieving repo content\", e)\\n',\n",
       " 'src/__init__.py': '',\n",
       " 'src/github_utils.py': 'from github import Github\\n\\ndef get_all_files(repo, path=\"\"):\\n    files = {}\\n    contents = repo.get_contents(path)\\n    for content in contents:\\n        if content.type == \"dir\":\\n            files[content.path] = get_all_files(repo, content.path)\\n        else:\\n            files[content.path] = content.content # base64\\n    return files'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_files_flatten = gu.flatten(decoded_files)\n",
    "decoded_files_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SourceCodeLoader with the decoded files\n",
    "class CustomCodeLoader(BaseLoader):\n",
    "    # Mapping of file extensions to their corresponding languages\n",
    "    extension_to_language = {\n",
    "        '.py': 'python',\n",
    "        '.ipynb': 'jupyter notebook',\n",
    "        '.r': 'R',\n",
    "        '.js': 'javascript',\n",
    "        # Add more mappings as needed\n",
    "    }\n",
    "\n",
    "    def __init__(self, files):\n",
    "        self.files = files\n",
    "\n",
    "    def get_language_from_extension(self, file_path):\n",
    "        _, extension = os.path.splitext(file_path)\n",
    "        return self.extension_to_language.get(extension.lower(), 'unknown')\n",
    "\n",
    "    def load(self):\n",
    "        for path, content in self.files.items():\n",
    "            if isinstance(content, str):\n",
    "                language = self.get_language_from_extension(path)\n",
    "                document = {\n",
    "                    'page_content': content,\n",
    "                    'metadata': {\n",
    "                        'path': path,\n",
    "                        'language': language\n",
    "                    }\n",
    "                }\n",
    "                yield document\n",
    "                \n",
    "custom_loader = CustomCodeLoader(decoded_files_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".gitignore unknown\n",
      "LICENSE unknown\n",
      "README.md unknown\n",
      "config/logs/local.conf unknown\n",
      "requirements.txt unknown\n",
      "sandbox.py python\n",
      "src/__init__.py python\n",
      "src/github_utils.py python\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE OF CUSTOM LOADER\n",
    "for document in custom_loader.load():\n",
    "    # Each document's 'content' is the file content\n",
    "    # and 'metadata' contains the file path and deduced language\n",
    "    print(document['metadata']['path'], document['metadata']['language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_content': '.env\\n.venv/\\n.vscode/\\n*.log\\n*.pyc',\n",
       "  'metadata': {'path': '.gitignore', 'language': 'unknown'}},\n",
       " {'page_content': 'MIT License\\n\\nCopyright (c) 2023 Hye Won (Nicole) Hwang\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n',\n",
       "  'metadata': {'path': 'LICENSE', 'language': 'unknown'}},\n",
       " {'page_content': \"# Auto-Readme\\n\\nAutomatically generate `readme.md` files for your repositories by parsing the code and summarizing it using Openai API.\\n\\n## Features\\n\\n- Parse GitHub repositories without downloading them.\\n- Summarize code using Langchain.\\n- Generate human-readable summaries with OpenAI's GPT model.\\n\\n## Prerequisites\\n\\n- Python 3.8+\\n- GitHub API Token (https://github.com/settings/tokens)\\n- OpenAI API Key (https://beta.openai.com/signup)\\n\\n## Installation\\n\\n1. Clone Repository\\n2. Create a virtual environment `python -m venv .venv` and install packages in `requirements.txt`\\n2. Create .env file at the root of directory\\n\\n```bash\\nGITHUB_API_TOKEN=<add-token-here>\\nOPENAI_API_TOKEN=<add-token-here>\\n```\\n\",\n",
       "  'metadata': {'path': 'README.md', 'language': 'unknown'}},\n",
       " {'page_content': \"[loggers]\\nkeys=root,src\\n\\n[handlers]\\nkeys=consoleHandler,fileHandler\\n\\n[formatters]\\nkeys=sampleFormatter\\n\\n[logger_root]\\nlevel=INFO\\nhandlers=consoleHandler,fileHandler\\npropagate=0\\n\\n[logger_src]\\nlevel=INFO\\nhandlers=consoleHandler,fileHandler\\nqualname=src\\npropagate=0\\n\\n[handler_consoleHandler]\\nclass=StreamHandler\\nlevel=INFO\\nformatter=sampleFormatter\\nargs=(sys.stdout,)\\n\\n[handler_fileHandler]\\nclass=FileHandler\\nlevel=INFO\\nformatter=sampleFormatter\\nargs=('config/logs/logs.log',)\\n\\n[formatter_sampleFormatter]\\nformat=%(asctime)s - %(name)s - %(levelname)s - %(message)s\\ndatefmt=%Y-%m-%d %H:%M:%S\",\n",
       "  'metadata': {'path': 'config/logs/local.conf', 'language': 'unknown'}},\n",
       " {'page_content': 'aiohttp==3.8.6\\naiosignal==1.3.1\\nasync-timeout==4.0.3\\nattrs==23.1.0\\ncertifi==2023.7.22\\ncffi==1.16.0\\ncharset-normalizer==3.3.2\\ncryptography==41.0.5\\nDeprecated==1.2.14\\nfrozenlist==1.4.0\\nidna==3.4\\nmultidict==6.0.4\\nopenai==0.28.1\\npycparser==2.21\\nPyGithub==2.1.1\\nPyJWT==2.8.0\\nPyNaCl==1.5.0\\npython-dateutil==2.8.2\\npython-dotenv==1.0.0\\nrequests==2.31.0\\nsix==1.16.0\\ntqdm==4.66.1\\ntyping_extensions==4.8.0\\nurllib3==2.0.7\\nwrapt==1.15.0\\nyarl==1.9.2\\n',\n",
       "  'metadata': {'path': 'requirements.txt', 'language': 'unknown'}},\n",
       " {'page_content': 'import os\\nimport argparse\\nimport logging\\nimport logging.config\\n\\nfrom dotenv import load_dotenv\\nfrom github import Github\\nimport src.github_utils as gu\\n\\nlogging.config.fileConfig(\"config/logs/local.conf\")\\nlogger = logging.getLogger(__name__)\\n\\nif __name__ == \"__main__\":\\n    parser = argparse.ArgumentParser(\\n        description=\"Auto-readme\"\\n    )\\n    parser.add_argument(\\n        \"-r\", \"--repo\", default=\"hyeniii/auto-readme\", help=\"Specify github repository to create a readme on\"\\n    )\\n    args = parser.parse_args()\\n\\n    # Load environment variables from .env file\\n    load_dotenv()\\n\\n    GITHUB_API_TOKEN = os.getenv(\"GITHUB_API_TOKEN\")\\n    OPEN_API_TOKEN = os.getenv(\"OPENAI_API_TOKEN\")\\n\\n    if GITHUB_API_TOKEN is None or OPEN_API_TOKEN is None:\\n        logger.error(\"API tokens not found in environment variables.\")\\n        exit(1)  # Exit the program if tokens are not set\\n\\n    try:\\n        g = Github(GITHUB_API_TOKEN)\\n        repo = g.get_repo(\"public-apis/public-apis\")\\n        print(repo.get_topics())\\n        logging.info(\"Recetriving data from %s\", repo.full_name)\\n        contents = repo.get_contents(\"\")\\n        all_files = gu.get_all_files(repo)\\n        print(all_files)\\n    except Exception as e:\\n        logging.error(\"Error occured in retrieving repo content\", e)\\n',\n",
       "  'metadata': {'path': 'sandbox.py', 'language': 'python'}},\n",
       " {'page_content': '',\n",
       "  'metadata': {'path': 'src/__init__.py', 'language': 'python'}},\n",
       " {'page_content': 'from github import Github\\n\\ndef get_all_files(repo, path=\"\"):\\n    files = {}\\n    contents = repo.get_contents(path)\\n    for content in contents:\\n        if content.type == \"dir\":\\n            files[content.path] = get_all_files(repo, content.path)\\n        else:\\n            files[content.path] = content.content # base64\\n    return files',\n",
       "  'metadata': {'path': 'src/github_utils.py', 'language': 'python'}}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = list(custom_loader.load())\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [document[\"page_content\"] for document in documents]\n",
    "metadata = [document[\"metadata\"] for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='.env\\n.venv/\\n.vscode/\\n*.log\\n*.pyc', metadata={'path': '.gitignore', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='MIT License\\n\\nCopyright (c) 2023 Hye Won (Nicole) Hwang', metadata={'path': 'LICENSE', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='Permission is hereby granted, free of charge, to any person obtaining a copy', metadata={'path': 'LICENSE', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='of this software and associated documentation files (the \"Software\"), to deal', metadata={'path': 'LICENSE', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='in the Software without restriction, including without limitation the rights', metadata={'path': 'LICENSE', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='to use, copy, modify, merge, publish, distribute, sublicense, and/or sell', metadata={'path': 'LICENSE', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='copies of the Software, and to permit persons to whom the Software is', metadata={'path': 'LICENSE', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='furnished to do so, subject to the following conditions:', metadata={'path': 'LICENSE', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='The above copyright notice and this permission notice shall be included in all', metadata={'path': 'LICENSE', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='copies or substantial portions of the Software.', metadata={'path': 'LICENSE', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR', metadata={'path': 'LICENSE', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,', metadata={'path': 'LICENSE', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE', metadata={'path': 'LICENSE', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER', metadata={'path': 'LICENSE', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,', metadata={'path': 'LICENSE', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.', metadata={'path': 'LICENSE', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='# Auto-Readme', metadata={'path': 'README.md', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='Automatically generate `readme.md` files for your repositories by parsing the code and summarizing', metadata={'path': 'README.md', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='and summarizing it using Openai API.', metadata={'path': 'README.md', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='## Features', metadata={'path': 'README.md', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='- Parse GitHub repositories without downloading them.\\n- Summarize code using Langchain.', metadata={'path': 'README.md', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content=\"- Generate human-readable summaries with OpenAI's GPT model.\", metadata={'path': 'README.md', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='## Prerequisites', metadata={'path': 'README.md', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='- Python 3.8+\\n- GitHub API Token (https://github.com/settings/tokens)', metadata={'path': 'README.md', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='- OpenAI API Key (https://beta.openai.com/signup)', metadata={'path': 'README.md', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='## Installation', metadata={'path': 'README.md', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='1. Clone Repository', metadata={'path': 'README.md', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='2. Create a virtual environment `python -m venv .venv` and install packages in `requirements.txt`', metadata={'path': 'README.md', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='2. Create .env file at the root of directory', metadata={'path': 'README.md', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='```bash\\nGITHUB_API_TOKEN=<add-token-here>\\nOPENAI_API_TOKEN=<add-token-here>\\n```', metadata={'path': 'README.md', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='[loggers]\\nkeys=root,src\\n\\n[handlers]\\nkeys=consoleHandler,fileHandler', metadata={'path': 'config/logs/local.conf', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='[formatters]\\nkeys=sampleFormatter', metadata={'path': 'config/logs/local.conf', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='[logger_root]\\nlevel=INFO\\nhandlers=consoleHandler,fileHandler\\npropagate=0', metadata={'path': 'config/logs/local.conf', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='[logger_src]\\nlevel=INFO\\nhandlers=consoleHandler,fileHandler\\nqualname=src\\npropagate=0', metadata={'path': 'config/logs/local.conf', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='[handler_consoleHandler]\\nclass=StreamHandler\\nlevel=INFO\\nformatter=sampleFormatter', metadata={'path': 'config/logs/local.conf', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='args=(sys.stdout,)', metadata={'path': 'config/logs/local.conf', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='[handler_fileHandler]\\nclass=FileHandler\\nlevel=INFO\\nformatter=sampleFormatter', metadata={'path': 'config/logs/local.conf', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content=\"args=('config/logs/logs.log',)\", metadata={'path': 'config/logs/local.conf', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='[formatter_sampleFormatter]\\nformat=%(asctime)s - %(name)s - %(levelname)s - %(message)s', metadata={'path': 'config/logs/local.conf', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='datefmt=%Y-%m-%d %H:%M:%S', metadata={'path': 'config/logs/local.conf', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='aiohttp==3.8.6\\naiosignal==1.3.1\\nasync-timeout==4.0.3\\nattrs==23.1.0\\ncertifi==2023.7.22\\ncffi==1.16.0', metadata={'path': 'requirements.txt', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='cffi==1.16.0\\ncharset-normalizer==3.3.2\\ncryptography==41.0.5\\nDeprecated==1.2.14\\nfrozenlist==1.4.0', metadata={'path': 'requirements.txt', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='frozenlist==1.4.0\\nidna==3.4\\nmultidict==6.0.4\\nopenai==0.28.1\\npycparser==2.21\\nPyGithub==2.1.1', metadata={'path': 'requirements.txt', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='PyGithub==2.1.1\\nPyJWT==2.8.0\\nPyNaCl==1.5.0\\npython-dateutil==2.8.2\\npython-dotenv==1.0.0', metadata={'path': 'requirements.txt', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='requests==2.31.0\\nsix==1.16.0\\ntqdm==4.66.1\\ntyping_extensions==4.8.0\\nurllib3==2.0.7\\nwrapt==1.15.0', metadata={'path': 'requirements.txt', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='wrapt==1.15.0\\nyarl==1.9.2', metadata={'path': 'requirements.txt', 'language': 'unknown', 'start_index': 0}),\n",
       " Document(page_content='import os\\nimport argparse\\nimport logging\\nimport logging.config', metadata={'path': 'sandbox.py', 'language': 'python', 'start_index': 0}),\n",
       " Document(page_content='from dotenv import load_dotenv\\nfrom github import Github\\nimport src.github_utils as gu', metadata={'path': 'sandbox.py', 'language': 'python', 'start_index': 0}),\n",
       " Document(page_content='logging.config.fileConfig(\"config/logs/local.conf\")\\nlogger = logging.getLogger(__name__)', metadata={'path': 'sandbox.py', 'language': 'python', 'start_index': 0}),\n",
       " Document(page_content='if __name__ == \"__main__\":\\n    parser = argparse.ArgumentParser(\\n        description=\"Auto-readme\"', metadata={'path': 'sandbox.py', 'language': 'python', 'start_index': 0}),\n",
       " Document(page_content=')\\n    parser.add_argument(', metadata={'path': 'sandbox.py', 'language': 'python', 'start_index': 0}),\n",
       " Document(page_content='\"-r\", \"--repo\", default=\"hyeniii/auto-readme\", help=\"Specify github repository to create a', metadata={'path': 'sandbox.py', 'language': 'python', 'start_index': 0}),\n",
       " Document(page_content='to create a readme on\"', metadata={'path': 'sandbox.py', 'language': 'python', 'start_index': 0}),\n",
       " Document(page_content=')\\n    args = parser.parse_args()', metadata={'path': 'sandbox.py', 'language': 'python', 'start_index': 0}),\n",
       " Document(page_content='# Load environment variables from .env file\\n    load_dotenv()', metadata={'path': 'sandbox.py', 'language': 'python', 'start_index': 0}),\n",
       " Document(page_content='GITHUB_API_TOKEN = os.getenv(\"GITHUB_API_TOKEN\")', metadata={'path': 'sandbox.py', 'language': 'python', 'start_index': 0}),\n",
       " Document(page_content='OPEN_API_TOKEN = os.getenv(\"OPENAI_API_TOKEN\")', metadata={'path': 'sandbox.py', 'language': 'python', 'start_index': 0}),\n",
       " Document(page_content='if GITHUB_API_TOKEN is None or OPEN_API_TOKEN is None:', metadata={'path': 'sandbox.py', 'language': 'python', 'start_index': 0}),\n",
       " Document(page_content='logger.error(\"API tokens not found in environment variables.\")', metadata={'path': 'sandbox.py', 'language': 'python', 'start_index': 0}),\n",
       " Document(page_content='exit(1)  # Exit the program if tokens are not set', metadata={'path': 'sandbox.py', 'language': 'python', 'start_index': 0}),\n",
       " Document(page_content='try:\\n        g = Github(GITHUB_API_TOKEN)\\n        repo = g.get_repo(\"public-apis/public-apis\")', metadata={'path': 'sandbox.py', 'language': 'python', 'start_index': 0}),\n",
       " Document(page_content='print(repo.get_topics())\\n        logging.info(\"Recetriving data from %s\", repo.full_name)', metadata={'path': 'sandbox.py', 'language': 'python', 'start_index': 0}),\n",
       " Document(page_content='contents = repo.get_contents(\"\")\\n        all_files = gu.get_all_files(repo)', metadata={'path': 'sandbox.py', 'language': 'python', 'start_index': 0}),\n",
       " Document(page_content='print(all_files)\\n    except Exception as e:', metadata={'path': 'sandbox.py', 'language': 'python', 'start_index': 0}),\n",
       " Document(page_content='logging.error(\"Error occured in retrieving repo content\", e)', metadata={'path': 'sandbox.py', 'language': 'python', 'start_index': 0}),\n",
       " Document(page_content='from github import Github', metadata={'path': 'src/github_utils.py', 'language': 'python', 'start_index': 0}),\n",
       " Document(page_content='def get_all_files(repo, path=\"\"):\\n    files = {}\\n    contents = repo.get_contents(path)', metadata={'path': 'src/github_utils.py', 'language': 'python', 'start_index': 0}),\n",
       " Document(page_content='for content in contents:\\n        if content.type == \"dir\":', metadata={'path': 'src/github_utils.py', 'language': 'python', 'start_index': 0}),\n",
       " Document(page_content='files[content.path] = get_all_files(repo, content.path)\\n        else:', metadata={'path': 'src/github_utils.py', 'language': 'python', 'start_index': 0}),\n",
       " Document(page_content='else:\\n            files[content.path] = content.content # base64\\n    return files', metadata={'path': 'src/github_utils.py', 'language': 'python', 'start_index': 0})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap  = 20,\n",
    "    length_function = len,\n",
    "    add_start_index = True,\n",
    ")\n",
    "\n",
    "documents = text_splitter.create_documents(texts, metadata)\n",
    "documents\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alelli/Documents/13 - Northwestern/09_Fall_2023/03_Text_Analytics/04_Final_Project/.venv/lib/python3.11/site-packages/pinecone/index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "#!pip install pinecone-client\n",
    "#!pip install tiktoken \n",
    "import pinecone\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "\n",
    "# --- Vector Storage --- \n",
    "\n",
    "# Initialize pinecone\n",
    "pinecone.init(api_key = PINECONE_API_TOKEN, environment = 'gcp-starter')\n",
    "\n",
    "INDEX_NAME = \"final-project\"\n",
    "\n",
    "# Delete exiting index\n",
    "#pinecone.delete_index(\"gen-ai-hw7-ali8110\")\n",
    "pinecone.delete_index(INDEX_NAME)\n",
    "\n",
    "# Create index from zero\n",
    "if INDEX_NAME not in pinecone.list_indexes():\n",
    "    pinecone.create_index(INDEX_NAME, dimension=1536, metric=\"cosine\")\n",
    "    \n",
    "# Connect to pinecone index\n",
    "index = pinecone.Index(index_name = INDEX_NAME)\n",
    "\n",
    "# Initialize the embeddings model with OpenAI\n",
    "embeddings_model = OpenAIEmbeddings(openai_api_key=OPEN_API_TOKEN, disallowed_special=())\n",
    "\n",
    "# Upload documents \n",
    "docs_upload = Pinecone.from_documents(chunks, embeddings_model, index_name = INDEX_NAME)\n",
    "\n",
    "# --- Set Retrieval ---\n",
    "retriever = docs_upload.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "model = ChatOpenAI(openai_api_key = OPEN_API_TOKEN,\n",
    "                   model_name = \"gpt-4\",\n",
    "                   temperature = 0.7)\n",
    "\n",
    "# Create ConversationalRetrievalChain\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(model, retriever = retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The text doesn't provide information about the language in which the code is written.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"In which language is the code written?\"\n",
    "chat_history = []\n",
    "response = qa_chain({\"question\": question, \"chat_history\": chat_history})\n",
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The purpose of the code is to automatically generate `readme.md` files for repositories by parsing the code and summarizing it.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is the purpose of the code?\"\n",
    "chat_history = []\n",
    "response = qa_chain({\"question\": question, \"chat_history\": chat_history})\n",
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The text doesn't provide specific information about what files are in the repository.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are the files in the repository?\"\n",
    "chat_history = []\n",
    "response = qa_chain({\"question\": question, \"chat_history\": chat_history})\n",
    "response[\"answer\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
